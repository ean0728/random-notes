{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d0b0971",
   "metadata": {},
   "source": [
    "代码实现路由需定义可能路径及决策逻辑。LangChain 和 LangGraph 等框架提供了专用组件和结构,LangGraph 的状态图结构尤其适合路由逻辑的可视化和实现。\n",
    "\n",
    "以下代码演示了使用 LangChain构建的简单智能体系统。\n",
    "系统设置一个“协调者”,根据请求意图(预订、信息、或不明确)将用户请求路由到不同的“子智能体”处理器。系统利用语言模型分类请求,并委托给相应处理函数,模拟多智能体架构中的基本委托模式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb9917f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‐‐‐ 预订请求示例 ‐‐‐\n",
      "\n",
      " --- 委托给预订处理器 ---\n",
      "最终结果 A: 预订处理器已处理请求:'帮我预订飞往伦敦的机票。'。结果:模拟预订动作。\n",
      "\n",
      "‐‐‐ 信息请求示例 ‐‐‐\n",
      "\n",
      "‐‐‐ 委托给信息处理器 ‐‐‐\n",
      "最终结果 B: 信息处理器已处理请求:'意大利的首都是哪里?'。结果:模拟信息检索。\n",
      "\n",
      "‐‐‐ 不明确请求示例 ‐‐‐\n",
      "\n",
      "‐‐‐ 委托给信息处理器 ‐‐‐\n",
      "最终结果 C: 信息处理器已处理请求:'讲讲量子物理。'。结果:模拟信息检索。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableBranch, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"API_KEY\"),\n",
    "    base_url=os.getenv(\"BASE_URL\"),\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "\n",
    "# 定义模拟子智能体处理器\n",
    "def booking_handler(request: str) -> str:\n",
    "    \"\"\"模拟预订智能体处理请求\"\"\"\n",
    "    print(\"\\n --- 委托给预订处理器 ---\")\n",
    "    return f\"预订处理器已处理请求:'{request}'。结果:模拟预订动作。\"\n",
    "\n",
    "\n",
    "def info_handler(request: str) -> str:\n",
    "    \"\"\"模拟信息智能体处理请求。\"\"\"\n",
    "    print(\"\\n‐‐‐ 委托给信息处理器 ‐‐‐\")\n",
    "    return f\"信息处理器已处理请求:'{request}'。结果:模拟信息检索。\"\n",
    "\n",
    "\n",
    "def unclear_handler(request: str) -> str:\n",
    "    \"\"\"处理无法委托的请求。\"\"\"\n",
    "    print(\"\\n‐‐‐ 处理不明确请求 ‐‐‐\")\n",
    "    return f\"协调者无法委托请求:'{request}'。请补充说明。\"\n",
    "\n",
    "\n",
    "# ‐‐‐ 定义协调者路由链(等同于 ADK 协调者指令)‐‐‐\n",
    "coordinator_router_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"分析用户请求,判断应由哪个专属处理器处理。\n",
    "        ‐ 若请求涉及预订机票或酒店,输出 'booker'。\n",
    "        ‐ 其他一般信息问题,输出 'info'。    \n",
    "        ‐ 若请求不明确或不属于上述类别,输出 'unclear'。\n",
    "        只输出一个词:'booker'、'info' 或 'unclear'。\"\"\"),\n",
    "        (\"user\", \"{request}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "coordinator_router_chain = coordinator_router_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 定义委托逻辑\n",
    "branches = {\n",
    "    \"booker\": RunnablePassthrough.assign(output=lambda x: booking_handler(x[\"request\"][\"request\"])),\n",
    "    \"info\": RunnablePassthrough.assign(output=lambda x: info_handler(x[\"request\"][\"request\"])),\n",
    "    \"unclear\": RunnablePassthrough.assign(output=lambda x: unclear_handler(x[\"request\"][\"request\"])),\n",
    "}\n",
    "\n",
    "delegation_branch = RunnableBranch(\n",
    "    (lambda x: x['decision'].strip() == 'booker', branches[\"booker\"]),\n",
    "    (lambda x: x['decision'].strip() == 'info', branches[\"info\"]),\n",
    "    branches[\"unclear\"],  # 默认分支\n",
    ")\n",
    "\n",
    "coordinator_agent = {\n",
    "    \"decision\": coordinator_router_chain,\n",
    "    \"request\": RunnablePassthrough()\n",
    "} | delegation_branch | (lambda x: x['output'])\n",
    "\n",
    " # ‐‐‐ 示例用法 ‐‐‐\n",
    "def main():\n",
    "    if not llm:\n",
    "        print(\"\\n 因 LLM 初始化失败,跳过执行。\")\n",
    "        return\n",
    "    \n",
    "    print(\"‐‐‐ 预订请求示例 ‐‐‐\")\n",
    "    request_a = \"帮我预订飞往伦敦的机票。\"\n",
    "    result_a = coordinator_agent.invoke({\"request\": request_a})\n",
    "    print(f\"最终结果 A: {result_a}\")\n",
    "    \n",
    "    print(\"\\n‐‐‐ 信息请求示例 ‐‐‐\")\n",
    "    request_b = \"意大利的首都是哪里?\"\n",
    "    result_b = coordinator_agent.invoke({\"request\": request_b})\n",
    "    print(f\"最终结果 B: {result_b}\")\n",
    "\n",
    "    print(\"\\n‐‐‐ 不明确请求示例 ‐‐‐\")\n",
    "    request_c = \"讲讲量子物理。\"\n",
    "    result_c = coordinator_agent.invoke({\"request\": request_c})\n",
    "    print(f\"最终结果 C: {result_c}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca54d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== 用户请求 ======\n",
      "帮我预订明天去上海的高铁票，并顺便查一下上海明天天气。\n",
      "\n",
      "====== 协调智能体执行中 ======\n",
      "\n",
      "\n",
      "--- 预订处理器 ---\n",
      "\n",
      "--- 信息处理器 ---\n",
      "\n",
      "====== 最终答复 ======\n",
      "根据您的需求，我已经完成了以下两项任务：\n",
      "\n",
      "1. **高铁票预订**：已为您成功预订明天前往上海的高铁票。预订信息已确认，请及时查看相关车次和座位详情。\n",
      "\n",
      "2. **天气查询**：已查询上海明天的天气情况。具体预报信息已获取，建议您出行前查看以做好相应准备。\n",
      "\n",
      "两项任务均已完成，如有其他需要，请随时告知。\n"
     ]
    }
   ],
   "source": [
    "# 可循环调用\n",
    "\n",
    "import os\n",
    "from typing import Dict, Any\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "# ============================================\n",
    "# 1. 配置 LLM\n",
    "# ============================================\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"API_KEY\"),\n",
    "    base_url=os.getenv(\"BASE_URL\"),\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# 2. 定义子智能体 / 工具（这里先用简单的模拟函数）\n",
    "# ============================================\n",
    "\n",
    "def booking_handler(request: str) -> str:\n",
    "    \"\"\"预订处理器：模拟机票/酒店预订逻辑\"\"\"\n",
    "    print(\"\\n--- 预订处理器 ---\")\n",
    "    return f\"【预订结果】已处理: {request}\"\n",
    "\n",
    "def info_handler(request: str) -> str:\n",
    "    \"\"\"信息处理器：模拟信息查询逻辑\"\"\"\n",
    "    print(\"\\n--- 信息处理器 ---\")\n",
    "    return f\"【信息结果】已处理: {request}\"\n",
    "\n",
    "def unclear_handler(request: str) -> str:\n",
    "    \"\"\"兜底处理器：当 route 未知或不支持时使用\"\"\"\n",
    "    print(\"\\n--- 不明确处理器 ---\")\n",
    "    return f\"【未能处理】请求不明确或路由未知: {request}\"\n",
    "\n",
    "# 把所有可用的“子智能体/工具”放进一个路由表里，方便按 route 名称调用\n",
    "HANDLERS: Dict[str, Any] = {\n",
    "    \"booker\": booking_handler,\n",
    "    \"info\": info_handler,\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 3. Planner：用 LLM 把“用户的大任务”拆成多个子任务列表\n",
    "#\n",
    "#   输入：用户的一句话（str）\n",
    "#   输出：一个 JSON 数组，每个元素是一个子任务:\n",
    "#       { \"route\": \"booker\" | \"info\", \"content\": \"交给该处理器的指令\" }\n",
    "#\n",
    "#   这里是“可循环调用”的关键：把任务变成 List[task]\n",
    "# ============================================\n",
    "\n",
    "planner_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            f\"\"\"你是任务规划器。\n",
    "用户会给你一个综合性请求，你需要把它拆成若干个可以按顺序执行的子任务列表。\n",
    "\n",
    "每个子任务是一个 JSON 对象，必须包含字段:\n",
    "- \"route\": 使用哪个处理器，只能是 \"booker\" 或 \"info\"\n",
    "- \"content\": 交给该处理器的中文指令\n",
    "\n",
    "要求输出：\n",
    "- 只输出一个合法的 JSON 数组字符串。\n",
    "- JSON 数组中的每个元素都是一个对象，包含两个字段：\n",
    "  - route：字符串，只能是 \"booker\" 或 \"info\"\n",
    "  - content：字符串，表示要发给该处理器的中文指令\n",
    "\n",
    "其他要求：\n",
    "- 不要在 JSON 外输出任何解释或额外文本。\n",
    "- 如果用户请求很简单，只需要一个子任务也可以。\n",
    "- 如果既要预订又要查询信息，就拆成两个及以上子任务。\n",
    "\"\"\"),\n",
    "        # 这里使用 {input}，使得整个链可以直接用 .invoke(\"用户输入\") 调用\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# JsonOutputParser 会把 LLM 输出的 JSON 字符串解析成 Python 对象（通常是 list[dict]）\n",
    "planner_chain = (\n",
    "    RunnableLambda(lambda x: {\"input\": x}) # 把字符串输入转成 dict\n",
    "    | planner_prompt \n",
    "    | llm \n",
    "    | JsonOutputParser()\n",
    ")\n",
    "# 输入: str\n",
    "# 输出: List[{\"route\": ..., \"content\": ...}]\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 4. Executor：对每个子任务分发到对应的子智能体（循环调用）\n",
    "#\n",
    "#   - dispatch_one_task: 单个任务 -> 单个结果\n",
    "#   - dispatch_runnable.map(): 对列表中的每个任务都调用一次 dispatch_one_task\n",
    "# ============================================\n",
    "\n",
    "def dispatch_one_task(task: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    根据 task[\"route\"] 字段选择对应的处理器，\n",
    "    再把 task[\"content\"] 交给处理器执行。\n",
    "    \"\"\"\n",
    "    route = task.get(\"route\")\n",
    "    content = task.get(\"content\", \"\")\n",
    "\n",
    "    # 根据 route 找到对应的 handler，找不到就走 unclear_handler\n",
    "    handler = HANDLERS.get(route, unclear_handler)\n",
    "    return handler(content)\n",
    "\n",
    "# RunnableLambda 可以把一个普通 Python 函数包装成 LCEL 的 Runnable\n",
    "dispatch_runnable = RunnableLambda(dispatch_one_task)\n",
    "\n",
    "# .map()：表示“对列表里的每一项都跑一遍 dispatch_runnable”\n",
    "# multi_tool_executor 的输入是 List[task]，输出是 List[result]\n",
    "multi_tool_executor = dispatch_runnable.map()\n",
    "\n",
    "# 组合成一个完整的“多工具执行链”：\n",
    "#   输入: 用户原始请求（str）\n",
    "#   1) planner_chain:         str -> List[task]\n",
    "#   2) multi_tool_executor:   List[task] -> List[result]\n",
    "#   3) RunnableLambda:        List[result] -> str（拼成一段文本）\n",
    "multi_tool_chain = (\n",
    "    planner_chain\n",
    "    | multi_tool_executor\n",
    "    | RunnableLambda(lambda results: \"\\n\".join(results))  # 把每个子任务结果换行拼接\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 5. Aggregator：用 LLM 把“原始请求 + 子任务结果”整合成一段最终回复\n",
    "# ============================================\n",
    "\n",
    "aggregator_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"你是总协调者。\n",
    "你会拿到：\n",
    "- 用户的原始请求\n",
    "- 各个子任务执行后的结果汇总（多行文本）\n",
    "\n",
    "请根据这些信息，用自然的中文给用户一段清晰的最终答复：\n",
    "- 可以分点说明每一步做了什么、结果如何\n",
    "- 不要输出 JSON\n",
    "- 保持语气专业、简洁\n",
    "\"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"用户原始请求:\\n{input}\\n\\n子任务执行结果:\\n{results}\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "aggregator_chain = aggregator_prompt | llm | StrOutputParser()\n",
    "# 输入: {\"input\": str, \"results\": str}\n",
    "# 输出: str\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 6. 最终协调智能体：Coordinator\n",
    "#\n",
    "#   输入：用户一句话（str）\n",
    "#   内部流程：\n",
    "#       1) multi_tool_chain 根据用户输入拆分任务并循环调用各子智能体\n",
    "#       2) aggregator_chain 用 LLM 整合原始请求 + 子任务结果\n",
    "#   输出：最终一段自然语言答复（str）\n",
    "# ============================================\n",
    "\n",
    "coordinator_agent = (\n",
    "    {\n",
    "        # 把用户原始输入传给 \"input\" 字段\n",
    "        \"input\": RunnablePassthrough(),\n",
    "        # 同时把同样的输入送给 multi_tool_chain，得到 \"results\"\n",
    "        \"results\": multi_tool_chain,\n",
    "    }\n",
    "    | aggregator_chain\n",
    ")\n",
    "# 类型：Runnable[str, str]\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 7. 示例：直接运行本文件时做一个简单测试\n",
    "# ============================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 例子：既要预订又要查信息，测试“循环调用多个子智能体”的效果\n",
    "    user_input = \"帮我预订明天去上海的高铁票，并顺便查一下上海明天天气。\"\n",
    "\n",
    "    print(\"====== 用户请求 ======\")\n",
    "    print(user_input)\n",
    "\n",
    "    print(\"\\n====== 协调智能体执行中 ======\\n\")\n",
    "    final_answer = coordinator_agent.invoke(user_input)\n",
    "\n",
    "    print(\"\\n====== 最终答复 ======\")\n",
    "    print(final_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b93d5851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== DeepSeek 协调者路由示例 ======\n",
      "\n",
      "\n",
      ">>> 用例 1：帮我预订明天去上海的高铁票和酒店。\n",
      "\n",
      "---------- 委托给【预订处理器】 ----------\n",
      "<<< 最终结果 1: 预订处理器已处理请求: '帮我预订明天去上海的高铁票和酒店。'。结果: 模拟预订动作。\n",
      "\n",
      ">>> 用例 2：世界最高的山峰是哪一座？\n",
      "\n",
      "---------- 委托给【信息处理器】 ----------\n",
      "<<< 最终结果 2: 信息处理器已处理请求: '世界最高的山峰是哪一座？'。结果: 模拟信息检索。\n",
      "\n",
      ">>> 用例 3：随便说一个有趣的事实。\n",
      "\n",
      "---------- 委托给【信息处理器】 ----------\n",
      "<<< 最终结果 3: 信息处理器已处理请求: '随便说一个有趣的事实。'。结果: 模拟信息检索。\n",
      "\n",
      ">>> 用例 4：查找下个月飞往东京的航班。\n",
      "\n",
      "---------- 委托给【预订处理器】 ----------\n",
      "<<< 最终结果 4: 预订处理器已处理请求: '查找下个月飞往东京的航班。'。结果: 模拟预订动作。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Dict, Any\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import (\n",
    "    RunnablePassthrough,\n",
    "    RunnableBranch,\n",
    "    RunnableLambda,\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# 1. 配置 DeepSeek LLM\n",
    "# ============================================\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"API_KEY\"),\n",
    "    base_url=os.getenv(\"BASE_URL\"),\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# 2. 定义“子智能体”的处理函数（模拟工具/子 Agent）\n",
    "# ============================================\n",
    "\n",
    "def booking_handler(request: str) -> str:\n",
    "    \"\"\"\n",
    "    处理机票、酒店等预订请求。\n",
    "    这里用 print + 返回字符串模拟实际动作。\n",
    "    \"\"\"\n",
    "    print(\"\\n---------- 委托给【预订处理器】 ----------\")\n",
    "    return f\"预订处理器已处理请求: '{request}'。结果: 模拟预订动作。\"\n",
    "\n",
    "\n",
    "def info_handler(request: str) -> str:\n",
    "    \"\"\"\n",
    "    处理一般信息/问答请求。\n",
    "    \"\"\"\n",
    "    print(\"\\n---------- 委托给【信息处理器】 ----------\")\n",
    "    return f\"信息处理器已处理请求: '{request}'。结果: 模拟信息检索。\"\n",
    "\n",
    "\n",
    "def unclear_handler(request: str) -> str:\n",
    "    \"\"\"\n",
    "    当协调者判断无法明确路由时的兜底处理。\n",
    "    \"\"\"\n",
    "    print(\"\\n---------- 处理【不明确请求】 ----------\")\n",
    "    return f\"协调者无法委托请求: '{request}'。请补充说明。\"\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 3. 定义“协调者 Router”Prompt + 决策链\n",
    "#\n",
    "#   功能：分析用户请求 → 只输出 'booker' / 'info' / 'unclear'\n",
    "#   注意：模板变量只有 {request}，避免出现 KeyError\n",
    "# ============================================\n",
    "\n",
    "coordinator_router_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"你是一个路由协调智能体。\n",
    "你的任务是分析用户的请求，并判断应该由哪个专属处理器来处理。\n",
    "\n",
    "规则：\n",
    "- 若请求涉及预订机票或酒店（比如预订航班、酒店、住宿等），输出：booker\n",
    "- 若是其他一般信息、知识问答、解释说明等问题，输出：info\n",
    "- 若请求不明确或不属于上述类别，输出：unclear\n",
    "\n",
    "只输出一个单词，不要额外解释：\n",
    "- booker\n",
    "- info\n",
    "- unclear\n",
    "\"\"\",\n",
    "        ),\n",
    "        (\"user\", \"{request}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ChatPromptTemplate 期望传入 dict，所以用一个小包装把 str → {\"request\": str}\n",
    "coordinator_router_chain = (\n",
    "    RunnableLambda(lambda x: {\"request\": x})\n",
    "    | coordinator_router_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "# 现在：\n",
    "#   输入: str (用户请求)\n",
    "#   输出: str (\"booker\" / \"info\" / \"unclear\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 4. 定义 LCEL 分支逻辑（相当于“协调者委托给子智能体”）\n",
    "#\n",
    "#   输入: {\"decision\": str, \"request\": str}\n",
    "#   输出: {\"decision\": str, \"request\": str, \"output\": str}\n",
    "# ============================================\n",
    "\n",
    "branches: Dict[str, Any] = {\n",
    "    \"booker\": RunnablePassthrough.assign(\n",
    "        output=lambda x: booking_handler(x[\"request\"])\n",
    "    ),\n",
    "    \"info\": RunnablePassthrough.assign(\n",
    "        output=lambda x: info_handler(x[\"request\"])\n",
    "    ),\n",
    "    \"unclear\": RunnablePassthrough.assign(\n",
    "        output=lambda x: unclear_handler(x[\"request\"])\n",
    "    ),\n",
    "}\n",
    "\n",
    "# RunnableBranch 会根据条件选择一个分支执行\n",
    "delegation_branch = RunnableBranch(\n",
    "    (lambda x: x[\"decision\"].strip() == \"booker\", branches[\"booker\"]),\n",
    "    (lambda x: x[\"decision\"].strip() == \"info\", branches[\"info\"]),\n",
    "    branches[\"unclear\"],  # 默认兜底分支\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# 5. 组合成一个“协调智能体” Coordinator Agent\n",
    "#\n",
    "#   输入: str（用户请求）\n",
    "#   流程：\n",
    "#       1) coordinator_router_chain: str -> \"booker\"/\"info\"/\"unclear\"\n",
    "#       2) RunnablePassthrough:      str -> 保留原始 request\n",
    "#       3) delegation_branch:        按 decision 选择对应 handler\n",
    "#       4) lambda 只取 x[\"output\"] 作为最终输出\n",
    "# ============================================\n",
    "\n",
    "coordinator_agent = (\n",
    "    {\n",
    "        # \"decision\"：给 router 链用\n",
    "        \"decision\": coordinator_router_chain,\n",
    "        # \"request\"：原始文本透传给后面的 handler\n",
    "        \"request\": RunnablePassthrough(),  # 这里接收的是 str\n",
    "    }\n",
    "    | delegation_branch\n",
    "    | (lambda x: x[\"output\"])  # 最终只保留 output 字段\n",
    ")\n",
    "# 类型：Runnable[str, str]\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 6. 示例调用\n",
    "# ============================================\n",
    "\n",
    "def main():\n",
    "    print(\"\\n====== DeepSeek 协调者路由示例 ======\\n\")\n",
    "\n",
    "    test_queries = [\n",
    "        \"帮我预订明天去上海的高铁票和酒店。\",\n",
    "        \"世界最高的山峰是哪一座？\",\n",
    "        \"随便说一个有趣的事实。\",\n",
    "        \"查找下个月飞往东京的航班。\",\n",
    "    ]\n",
    "\n",
    "    for i, q in enumerate(test_queries, start=1):\n",
    "        print(f\"\\n>>> 用例 {i}：{q}\")\n",
    "        result = coordinator_agent.invoke(q)  # 直接传 str\n",
    "        print(f\"<<< 最终结果 {i}: {result}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
